"""
ä¿®æ­£ã•ã‚ŒãŸJamMa-FDAFT Complete Demonstration Script

ä¸»ãªä¿®æ­£ç‚¹ï¼š
- JamMaã®å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ä½¿ç”¨å¯¾å¿œ
- è¨­å®šã®æ•´åˆæ€§ã‚’ç¢ºä¿
- FDAFTã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼ã¨JamMaæ¬¡å…ƒã®é©åˆæ€§å‘ä¸Š
- çµ±åˆãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®å®‰å®šåŒ–
"""

import sys
import os
import numpy as np
import cv2
import matplotlib.pyplot as plt
import time
import torch
import torch.nn as nn

# Add src to path
sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'src'))

try:
    from jamma_fdaft.backbone_fdaft import FDAFTEncoder
    from jamma.jamma import JamMa
    from jamma.backbone import CovNextV2_nano
    from config.default import get_cfg_defaults
    from utils.plotting import make_matching_figures
    from utils.dataset import read_megadepth_color
    import torch.nn.functional as F
    from utils.misc import lower_config
except ImportError as e:
    print(f"Error importing modules: {e}")
    print("Please ensure the project is properly set up.")
    sys.exit(1)


class JamMaFDAFTDemo(nn.Module):
    """
    JamMa-FDAFTçµ±åˆãƒ¢ãƒ‡ãƒ«ï¼ˆãƒ‡ãƒ¢ç”¨ï¼‰
    FDAFTã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼ + JamMaã®å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã‚’çµ„ã¿åˆã‚ã›
    """
    
    def __init__(self, config, pretrained_jamma='official'):
        super().__init__()
        self.config = config
        
        # FDAFTã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼ã‚’åˆæœŸåŒ–ï¼ˆJamMaã®æ¬¡å…ƒã«åˆã‚ã›ã‚‹ï¼‰
        self.fdaft_backbone = FDAFTEncoder.from_config(config)
        
        # JamMaã®å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿
        self.jamma_backbone = CovNextV2_nano()
        self.jamma_matcher = JamMa(config=config.JAMMA, profiler=None)
        
        # JamMaã®å­¦ç¿’æ¸ˆã¿é‡ã¿ã‚’èª­ã¿è¾¼ã¿
        if pretrained_jamma == 'official':
            try:
                state_dict = torch.hub.load_state_dict_from_url(
                    'https://github.com/leoluxxx/JamMa/releases/download/v0.1/jamma.ckpt',
                    file_name='jamma.ckpt')['state_dict']
                
                # JamMaéƒ¨åˆ†ã®ã¿èª­ã¿è¾¼ã¿ï¼ˆbackboneã¯é™¤å¤–ï¼‰
                jamma_state_dict = {}
                for key, value in state_dict.items():
                    if key.startswith('matcher.'):
                        # matcher.xxx -> xxx ã«å¤‰æ›
                        new_key = key[8:]  # "matcher."ã‚’é™¤å»
                        jamma_state_dict[new_key] = value
                
                self.jamma_matcher.load_state_dict(jamma_state_dict, strict=False)
                print("âœ“ JamMaå­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿å®Œäº†")
                
            except Exception as e:
                print(f"JamMaå­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—: {e}")
                print("ã‚¹ã‚¯ãƒ©ãƒƒãƒã‹ã‚‰åˆæœŸåŒ–ã—ã¾ã™")
        
        # æ¬¡å…ƒé©å¿œãƒ¬ã‚¤ãƒ¤ãƒ¼ï¼ˆFDAFTã‹ã‚‰JamMaã¸ã®æ©‹æ¸¡ã—ï¼‰
        fdaft_dim = 256  # FDAFTå‡ºåŠ›æ¬¡å…ƒ
        jamma_dim = 256  # JamMaæœŸå¾…æ¬¡å…ƒ
        
        self.dimension_adapter_8 = nn.Sequential(
            nn.Conv2d(fdaft_dim, jamma_dim, kernel_size=1),
            nn.BatchNorm2d(jamma_dim),
            nn.ReLU(inplace=True)
        ) if fdaft_dim != jamma_dim else nn.Identity()
        
        self.dimension_adapter_4 = nn.Sequential(
            nn.Conv2d(128, 128, kernel_size=1),  # Fine level adaptation
            nn.BatchNorm2d(128),
            nn.ReLU(inplace=True)
        )
    
    def forward(self, data):
        """çµ±åˆãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰ãƒ‘ã‚¹"""
        # 1. FDAFTã§ç‰¹å¾´æŠ½å‡º
        self.fdaft_backbone(data)
        
        # 2. æ¬¡å…ƒé©å¿œ
        data['feat_8_0'] = self.dimension_adapter_8(data['feat_8_0'])
        data['feat_8_1'] = self.dimension_adapter_8(data['feat_8_1'])
        data['feat_4_0'] = self.dimension_adapter_4(data['feat_4_0'])
        data['feat_4_1'] = self.dimension_adapter_4(data['feat_4_1'])
        
        # 3. JamMaã§ãƒãƒƒãƒãƒ³ã‚°
        return self.jamma_matcher(data, mode='test')


def create_planetary_image_pair():
    """
    æƒ‘æ˜Ÿè¡¨é¢ç”»åƒãƒšã‚¢ã®ç”Ÿæˆï¼ˆæ”¹è‰¯ç‰ˆï¼‰
    """
    print("  Creating synthetic planetary surface images...")
    np.random.seed(42)
    size = (512, 512)
    
    # ã‚ˆã‚Šç¾å®Ÿçš„ãªåœ°å½¢ç”Ÿæˆ
    x, y = np.meshgrid(np.linspace(0, 10, size[1]), np.linspace(0, 10, size[0]))
    
    # å¤šã‚¹ã‚±ãƒ¼ãƒ«åœ°å½¢ç”Ÿæˆ
    terrain1 = (
        np.sin(x) * np.cos(y) +                    # å¤§è¦æ¨¡ç‰¹å¾´
        0.5 * np.sin(2*x) * np.cos(3*y) +         # ä¸­è¦æ¨¡ç‰¹å¾´  
        0.3 * np.sin(5*x) * np.cos(2*y) +         # å°è¦æ¨¡ç‰¹å¾´
        0.2 * np.sin(8*x) * np.cos(5*y) +         # ç´°éƒ¨
        0.1 * np.random.normal(0, 1, size)        # ãƒã‚¤ã‚º
    )
    
    # ã‚¯ãƒ¬ãƒ¼ã‚¿ãƒ¼æ§˜ã®å††å½¢çªªåœ°ã‚’è¿½åŠ 
    crater_positions = [
        (128, 150, 25),  # (center_x, center_y, radius)
        (300, 200, 35),
        (400, 400, 20),
        (150, 350, 30)
    ]
    
    for cx, cy, radius in crater_positions:
        y_coords, x_coords = np.ogrid[:size[0], :size[1]]
        crater_mask = (x_coords - cx)**2 + (y_coords - cy)**2 <= radius**2
        
        # ç¾å®Ÿçš„ãªã‚¯ãƒ¬ãƒ¼ã‚¿ãƒ¼ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«
        distance = np.sqrt((x_coords - cx)**2 + (y_coords - cy)**2)
        crater_depth = np.exp(-distance**2 / (2 * (radius/2)**2)) * 0.4
        
        terrain1[crater_mask] -= crater_depth[crater_mask]
    
    # 2ç•ªç›®ã®ç”»åƒï¼ˆå¹¾ä½•å¤‰æ›é©ç”¨ï¼‰
    center = (size[1]//2, size[0]//2)
    angle = 12  # degrees
    scale = 0.95
    
    M = cv2.getRotationMatrix2D(center, angle, scale)
    M[0, 2] += 25  # translation x
    M[1, 2] += 15  # translation y
    
    image2 = cv2.warpAffine(terrain1, M, (size[1], size[0]))
    
    # ç…§æ˜å¤‰åŒ–ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆ
    illumination_gradient_x = np.linspace(0.85, 1.15, size[1])
    illumination_gradient_y = np.linspace(1.05, 0.95, size[0])
    illumination_map = np.outer(illumination_gradient_y, illumination_gradient_x)
    
    image2 = image2 * illumination_map + 0.1
    
    # [0, 255]ç¯„å›²ã«æ­£è¦åŒ–
    image1 = ((terrain1 - terrain1.min()) / (terrain1.max() - terrain1.min()) * 255).astype(np.uint8)
    image2 = ((image2 - image2.min()) / (image2.max() - image2.min()) * 255).astype(np.uint8)
    
    print("  âœ“ Synthetic planetary images created successfully!")
    return image1, image2


def prepare_data_batch(image1, image2):
    """
    JamMa-FDAFTå‡¦ç†ç”¨ã®ãƒ‡ãƒ¼ã‚¿ãƒãƒƒãƒæº–å‚™
    """
    # RGBå½¢å¼ã«å¤‰æ›ï¼ˆ3ãƒãƒ£ãƒ³ãƒãƒ«ï¼‰
    if len(image1.shape) == 2:
        image1_rgb = np.stack([image1, image1, image1], axis=2)
        image2_rgb = np.stack([image2, image2, image2], axis=2)
    else:
        image1_rgb = image1
        image2_rgb = image2
    
    # MegaDepthã‚¹ã‚¿ã‚¤ãƒ«ã®å‰å‡¦ç†ï¼ˆJamMaã¨äº’æ›æ€§ã‚’ä¿ã¤ï¼‰
    image1_tensor, scale1, mask1, prepad_size1 = read_megadepth_color(
        None, resize=832, df=16, padding=True
    )
    image2_tensor, scale2, mask2, prepad_size2 = read_megadepth_color(
        None, resize=832, df=16, padding=True
    )
    
    # å®Ÿéš›ã®ç”»åƒãƒ‡ãƒ¼ã‚¿ã§ç½®ãæ›ãˆ
    image1_processed = torch.from_numpy(image1_rgb).float().permute(2, 0, 1) / 255.0
    image2_processed = torch.from_numpy(image2_rgb).float().permute(2, 0, 1) / 255.0
    
    # ãƒªã‚µã‚¤ã‚ºã¨ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°
    image1_processed = F.interpolate(image1_processed.unsqueeze(0), size=(832, 832), mode='bilinear').squeeze(0)
    image2_processed = F.interpolate(image2_processed.unsqueeze(0), size=(832, 832), mode='bilinear').squeeze(0)
    
    # æ­£è¦åŒ–ï¼ˆImageNetçµ±è¨ˆï¼‰
    imagenet_mean = torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1)
    imagenet_std = torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1)
    
    image1_processed = (image1_processed - imagenet_mean) / imagenet_std
    image2_processed = (image2_processed - imagenet_mean) / imagenet_std
    
    # ãƒãƒƒãƒæ¬¡å…ƒã‚’è¿½åŠ 
    image1_batch = image1_processed.unsqueeze(0)  # [1, 3, H, W]
    image2_batch = image2_processed.unsqueeze(0)  # [1, 3, H, W]
    
    # ãƒã‚¹ã‚¯ç”Ÿæˆ
    mask1 = torch.ones(1, 832, 832).bool()
    mask2 = torch.ones(1, 832, 832).bool()
    
    # ãƒ‡ãƒ¼ã‚¿è¾æ›¸ä½œæˆ
    data = {
        'imagec_0': image1_batch,
        'imagec_1': image2_batch,
        'mask0': mask1,
        'mask1': mask2,
        'dataset_name': ['JamMa-FDAFT-Demo'],
        'scene_id': 'demo_scene',
        'pair_id': 0,
        'pair_names': [('demo_image1.png', 'demo_image2.png')]
    }
    
    return data


def create_demo_config():
    """
    ãƒ‡ãƒ¢ç”¨è¨­å®šã®ä½œæˆï¼ˆJamMaäº’æ›ï¼‰
    """
    # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®šå–å¾—
    config = get_cfg_defaults()
    
    # JamMaäº’æ›ã®è¨­å®š
    config.JAMMA.RESOLUTION = (8, 2)
    config.JAMMA.FINE_WINDOW_SIZE = 5
    config.JAMMA.COARSE.D_MODEL = 256  # JamMaã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
    config.JAMMA.FINE.D_MODEL = 128    # JamMaã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
    
    # ãƒãƒƒãƒãƒ³ã‚°é–¾å€¤
    config.JAMMA.MATCH_COARSE.USE_SM = True
    config.JAMMA.MATCH_COARSE.THR = 0.2
    config.JAMMA.MATCH_COARSE.BORDER_RM = 2
    config.JAMMA.FINE.THR = 0.1
    config.JAMMA.FINE.INFERENCE = True
    config.JAMMA.MATCH_COARSE.INFERENCE = True
    
    # FDAFTè¨­å®š
    config.FDAFT = config.__class__()
    config.FDAFT.NUM_LAYERS = 3
    config.FDAFT.SIGMA_0 = 1.0
    config.FDAFT.USE_STRUCTURED_FORESTS = True
    config.FDAFT.MAX_KEYPOINTS = 1000  # ãƒ‡ãƒ¢ç”¨ã«å‰Šæ¸›
    config.FDAFT.NMS_RADIUS = 5
    
    return config


def demonstrate_jamma_fdaft():
    """ãƒ¡ã‚¤ãƒ³å®Ÿæ¼”é–¢æ•°"""
    print("JamMa-FDAFTçµ±åˆãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Ÿæ¼”")
    print("=" * 60)
    print("ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£: Input Images â†’ FDAFT Encoder â†’ Joint Mamba (JEGO) â†’ C2F Matching")
    print("ç‰¹å¾´: JamMaã®å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨")
    print()
    
    # ã‚¹ãƒ†ãƒƒãƒ—1: ã‚µãƒ³ãƒ—ãƒ«ç”»åƒä½œæˆ
    print("Step 1: åˆæˆæƒ‘æ˜Ÿç”»åƒã®ä½œæˆ...")
    start_time = time.time()
    image1, image2 = create_planetary_image_pair()
    creation_time = time.time() - start_time
    print(f"  âœ“ ç”»åƒä½œæˆå®Œäº† {creation_time:.2f} ç§’")
    
    # å…¥åŠ›ç”»åƒè¡¨ç¤º
    print("\nå…¥åŠ›ç”»åƒã‚’è¡¨ç¤ºä¸­...")
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))
    
    ax1.imshow(image1, cmap='gray')
    ax1.set_title('æƒ‘æ˜Ÿç”»åƒ1 (å‚ç…§)', fontsize=14, fontweight='bold')
    ax1.axis('off')
    
    ax2.imshow(image2, cmap='gray')
    ax2.set_title('æƒ‘æ˜Ÿç”»åƒ2 (å¤‰æ›æ¸ˆã¿)', fontsize=14, fontweight='bold')
    ax2.axis('off')
    
    plt.tight_layout()
    plt.show()
    
    # ã‚¹ãƒ†ãƒƒãƒ—2: JamMa-FDAFTåˆæœŸåŒ–
    print("\nStep 2: JamMa-FDAFT ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–...")
    
    # ä¸€è²«ã—ãŸè¨­å®šä½œæˆ
    config = create_demo_config()
    _config = lower_config(config)
    
    print("  JamMa-FDAFTçµ±åˆãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–ä¸­...")
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    model = JamMaFDAFTDemo(config, pretrained_jamma='official').to(device)
    model.eval()
    
    print("  âœ“ JamMa-FDAFTåˆæœŸåŒ–æˆåŠŸ!")
    
    # ãƒ¢ãƒ‡ãƒ«æƒ…å ±è¡¨ç¤º
    print("\nãƒ¢ãƒ‡ãƒ«ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£æƒ…å ±:")
    total_params = sum(p.numel() for p in model.parameters())
    print(f"  ç·ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: {total_params:,}")
    print(f"  FDAFT Encoder: æƒ‘æ˜Ÿç”»åƒç‰¹åŒ–ç‰¹å¾´æŠ½å‡º")
    print(f"  JamMa Matcher: å­¦ç¿’æ¸ˆã¿Joint Mamba + C2F ãƒãƒƒãƒãƒ³ã‚°")
    print(f"  å‡ºåŠ›æ¬¡å…ƒ: Coarse={config.JAMMA.COARSE.D_MODEL}, Fine={config.JAMMA.FINE.D_MODEL}")
    
    # ã‚¹ãƒ†ãƒƒãƒ—3: ãƒ‡ãƒ¼ã‚¿æº–å‚™ã¨æ¨è«–å®Ÿè¡Œ
    print("\nStep 3: JamMa-FDAFT ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Ÿè¡Œ...")
    start_time = time.time()
    
    try:
        # ãƒ‡ãƒ¼ã‚¿ãƒãƒƒãƒæº–å‚™
        data = prepare_data_batch(image1, image2)
        
        # ãƒ‡ãƒã‚¤ã‚¹ã«ç§»å‹•
        for key, value in data.items():
            if isinstance(value, torch.Tensor):
                data[key] = value.to(device)
        
        with torch.no_grad():
            print("  FDAFT + JamMaçµ±åˆå‡¦ç†ä¸­...")
            # çµ±åˆãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Ÿè¡Œ
            model(data)
        
        processing_time = time.time() - start_time
        print(f"  âœ“ ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Œäº† {processing_time:.2f} ç§’")
        
    except Exception as e:
        print(f"  âœ— å‡¦ç†ä¸­ã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        traceback.print_exc()
        return False
    
    # ã‚¹ãƒ†ãƒƒãƒ—4: çµæœåˆ†æ
    print("\nStep 4: çµæœåˆ†æ...")
    
    # ãƒãƒƒãƒãƒ³ã‚°çµæœæŠ½å‡º
    num_matches = len(data.get('mkpts0_f', []))
    coarse_matches = len(data.get('mkpts0_c', []))
    
    print(f"  ç²—ãƒ¬ãƒ™ãƒ«ãƒãƒƒãƒæ¤œå‡º: {coarse_matches}")
    print(f"  ç´°ãƒ¬ãƒ™ãƒ«ãƒãƒƒãƒæ¤œå‡º: {num_matches}")
    
    # ã‚¹ãƒ†ãƒƒãƒ—5: çµæœå¯è¦–åŒ–
    print(f"\nStep 5: çµæœå¯è¦–åŒ–...")
    try:
        if num_matches > 0:
            # ãƒãƒƒãƒãƒ³ã‚°å¯è¦–åŒ–ä½œæˆ
            make_matching_figures(data, mode='evaluation')
            print("  âœ“ å¯è¦–åŒ–å®Œäº†")
        else:
            print("  âš  å¯è¦–åŒ–ç”¨ãƒãƒƒãƒãªã—")
            
    except Exception as e:
        print(f"  âœ— å¯è¦–åŒ–ã‚¨ãƒ©ãƒ¼: {e}")
    
    # æœ€çµ‚ã¾ã¨ã‚
    print("\n" + "="*60)
    print("JAMMA-FDAFT å®Ÿæ¼”ã¾ã¨ã‚")
    print("="*60)
    print(f"å‡¦ç†æ™‚é–“: {processing_time:.2f} ç§’")
    print(f"æœ€çµ‚ãƒãƒƒãƒæ•°: {num_matches}")
    
    if num_matches >= 8:
        print("âœ“ æˆåŠŸ: JamMa-FDAFTãŒæƒ‘æ˜Ÿç”»åƒã®ãƒãƒƒãƒãƒ³ã‚°ã«æˆåŠŸ!")
        print("  çµ±åˆãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ãŒå®Ÿè¨¼:")
        print("  - FDAFT: å¼±ã„è¡¨é¢ãƒ†ã‚¯ã‚¹ãƒãƒ£ç”¨ã®å …ç‰¢ãªç‰¹å¾´æŠ½å‡º")
        print("  - JamMaå­¦ç¿’æ¸ˆã¿: åŠ¹ç‡çš„ãªé•·è·é›¢ç‰¹å¾´ç›¸äº’ä½œç”¨")
        print("  - C2F ãƒãƒƒãƒãƒ³ã‚°: éšå±¤çš„ãƒãƒƒãƒãƒ³ã‚°ã¨ã‚µãƒ–ãƒ”ã‚¯ã‚»ãƒ«ç²¾ç´°åŒ–")
        print("  - æƒ‘æ˜Ÿæœ€é©åŒ–: å›°é›£ãªè¡¨é¢ã§ã®æ€§èƒ½å‘ä¸Š")
    else:
        print("âš  é™å®šçš„æˆåŠŸ: å°‘æ•°ã®ãƒãƒƒãƒã®ã¿æ¤œå‡º")
        print("  åŸå› ã¨ã—ã¦è€ƒãˆã‚‰ã‚Œã‚‹ã‚‚ã®:")
        print("  - ãƒ‡ãƒ¢ç”¨ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚ºã®ç¸®å°ï¼ˆå®Œå…¨ãƒ¢ãƒ‡ãƒ«ã§ã‚ˆã‚Šè‰¯ã„çµæœï¼‰")
        print("  - åˆæˆç”»åƒã®ç‰¹æ€§ãŒå›°é›£")
        print("  - ç‰¹å®šç”»åƒã‚¿ã‚¤ãƒ—ç”¨ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿èª¿æ•´ã®å¿…è¦æ€§")
    
    print(f"\næ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—:")
    print(f"  - å®Ÿéš›ã®æƒ‘æ˜Ÿãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆï¼ˆç«æ˜Ÿã€æœˆãªã©ï¼‰ã§ã®è¨“ç·´")
    print(f"  - å®Ÿè¡Œ: python train_jammf.py configs/data/megadepth_trainval_832.py configs/jamma_fdaft/outdoor/final.py")
    print(f"  - ãƒ†ã‚¹ãƒˆ: python test_jammf.py configs/data/megadepth_test_1500.py configs/jamma_fdaft/outdoor/test.py")
    
    return True


if __name__ == "__main__":
    """å®Ÿæ¼”ã‚¹ã‚¯ãƒªãƒ—ãƒˆã®ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆ"""
    try:
        # matplotlibè¨­å®š
        try:
            import matplotlib
            matplotlib.use('TkAgg')
        except:
            matplotlib.use('Agg')
            print("æ³¨æ„: éå¯¾è©±å‹matplotlibãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã‚’ä½¿ç”¨")
        
        success = demonstrate_jamma_fdaft()
        
        if success:
            print(f"\nğŸ‰ JamMa-FDAFT ãƒ‡ãƒ¢ãŒæ­£å¸¸ã«å®Œäº†ã—ã¾ã—ãŸ!")
            input("Enterã‚­ãƒ¼ã§çµ‚äº†...")
        else:
            print(f"\nâŒ ãƒ‡ãƒ¢ãŒå¤±æ•—ã—ã¾ã—ãŸã€‚ä¸Šè¨˜ã®ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
            
    except KeyboardInterrupt:
        print(f"\n\nãƒ‡ãƒ¢ãŒãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ã‚ˆã£ã¦ä¸­æ–­ã•ã‚Œã¾ã—ãŸã€‚")
    except Exception as e:
        print(f"\nâŒ äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        traceback.print_exc()
        
    sys.exit(0)